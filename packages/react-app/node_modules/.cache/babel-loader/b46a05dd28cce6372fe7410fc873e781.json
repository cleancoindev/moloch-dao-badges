{"ast":null,"code":"'use strict';\n\nconst {\n  DAGLink,\n  DAGNode\n} = require('ipld-dag-pb');\n\nconst UnixFS = require('ipfs-unixfs');\n\nconst multihashing = require('multihashing-async');\n\nconst Dir = require('./dir');\n\nconst persist = require('./utils/persist');\n\nconst Bucket = require('hamt-sharding');\n\nconst extend = require('deep-extend');\n\nconst hashFn = async function (value) {\n  const hash = await multihashing(Buffer.from(value, 'utf8'), 'murmur3-128'); // Multihashing inserts preamble of 2 bytes. Remove it.\n  // Also, murmur3 outputs 128 bit but, accidently, IPFS Go's\n  // implementation only uses the first 64, so we must do the same\n  // for parity..\n\n  const justHash = hash.slice(2, 10);\n  const length = justHash.length;\n  const result = Buffer.alloc(length); // TODO: invert buffer because that's how Go impl does it\n\n  for (let i = 0; i < length; i++) {\n    result[length - i - 1] = justHash[i];\n  }\n\n  return result;\n};\n\nhashFn.code = 0x22; // TODO: get this from multihashing-async?\n\nconst defaultOptions = {\n  hashFn: hashFn\n};\n\nclass DirSharded extends Dir {\n  constructor(props, options) {\n    options = extend({}, defaultOptions, options);\n    super(props, options);\n    this._bucket = Bucket(options);\n  }\n\n  async put(name, value) {\n    await this._bucket.put(name, value);\n  }\n\n  get(name) {\n    return this._bucket.get(name);\n  }\n\n  childCount() {\n    return this._bucket.leafCount();\n  }\n\n  directChildrenCount() {\n    return this._bucket.childrenCount();\n  }\n\n  onlyChild() {\n    return this._bucket.onlyChild();\n  }\n\n  async *eachChildSeries() {\n    for await (const {\n      key,\n      value\n    } of this._bucket.eachLeafSeries()) {\n      yield {\n        key,\n        child: value\n      };\n    }\n  }\n\n  async *flush(path, ipld) {\n    for await (const entry of flush(path, this._bucket, ipld, this.options)) {\n      yield entry;\n    }\n  }\n\n}\n\nmodule.exports = DirSharded;\nmodule.exports.hashFn = hashFn;\n\nasync function* flush(path, bucket, ipld, options) {\n  const children = bucket._children;\n  const links = [];\n\n  for (let i = 0; i < children.length; i++) {\n    const child = children.get(i);\n\n    if (!child) {\n      continue;\n    }\n\n    const labelPrefix = i.toString(16).toUpperCase().padStart(2, '0');\n\n    if (Bucket.isBucket(child)) {\n      let shard;\n\n      for await (const subShard of await flush('', child, ipld, options)) {\n        shard = subShard;\n      }\n\n      links.push(new DAGLink(labelPrefix, shard.node.size, shard.cid));\n    } else if (typeof child.value.flush === 'function') {\n      const dir = child.value;\n      let flushedDir;\n\n      for await (const entry of dir.flush(dir.path, ipld)) {\n        flushedDir = entry;\n        yield flushedDir;\n      }\n\n      const label = labelPrefix + child.key;\n      links.push(new DAGLink(label, flushedDir.node.size, flushedDir.cid));\n    } else {\n      const value = child.value;\n\n      if (!value.node) {\n        if (value.cid) {\n          value.node = await ipld.get(value.cid);\n        } else {\n          continue;\n        }\n      }\n\n      const label = labelPrefix + child.key;\n      const size = value.node.length || value.node.size || value.node.Size;\n      links.push(new DAGLink(label, size, value.cid));\n    }\n  } // go-ipfs uses little endian, that's why we have to\n  // reverse the bit field before storing it\n\n\n  const data = Buffer.from(children.bitField().reverse());\n  const dir = new UnixFS('hamt-sharded-directory', data);\n  dir.fanout = bucket.tableSize();\n  dir.hashType = options.hashFn.code;\n  const node = new DAGNode(dir.marshal(), links);\n  const cid = await persist(node, ipld, options);\n  yield {\n    cid,\n    node,\n    unixfs: dir,\n    path\n  };\n}","map":{"version":3,"sources":["/home/samkuhlmann/Documents/ody/moloch/moloch-dao-badges/node_modules/ipfs-unixfs-importer/src/dir-sharded.js"],"names":["DAGLink","DAGNode","require","UnixFS","multihashing","Dir","persist","Bucket","extend","hashFn","value","hash","Buffer","from","justHash","slice","length","result","alloc","i","code","defaultOptions","DirSharded","constructor","props","options","_bucket","put","name","get","childCount","leafCount","directChildrenCount","childrenCount","onlyChild","eachChildSeries","key","eachLeafSeries","child","flush","path","ipld","entry","module","exports","bucket","children","_children","links","labelPrefix","toString","toUpperCase","padStart","isBucket","shard","subShard","push","node","size","cid","dir","flushedDir","label","Size","data","bitField","reverse","fanout","tableSize","hashType","marshal","unixfs"],"mappings":"AAAA;;AAEA,MAAM;AACJA,EAAAA,OADI;AAEJC,EAAAA;AAFI,IAGFC,OAAO,CAAC,aAAD,CAHX;;AAIA,MAAMC,MAAM,GAAGD,OAAO,CAAC,aAAD,CAAtB;;AACA,MAAME,YAAY,GAAGF,OAAO,CAAC,oBAAD,CAA5B;;AACA,MAAMG,GAAG,GAAGH,OAAO,CAAC,OAAD,CAAnB;;AACA,MAAMI,OAAO,GAAGJ,OAAO,CAAC,iBAAD,CAAvB;;AACA,MAAMK,MAAM,GAAGL,OAAO,CAAC,eAAD,CAAtB;;AACA,MAAMM,MAAM,GAAGN,OAAO,CAAC,aAAD,CAAtB;;AAEA,MAAMO,MAAM,GAAG,gBAAgBC,KAAhB,EAAuB;AACpC,QAAMC,IAAI,GAAG,MAAMP,YAAY,CAACQ,MAAM,CAACC,IAAP,CAAYH,KAAZ,EAAmB,MAAnB,CAAD,EAA6B,aAA7B,CAA/B,CADoC,CAGpC;AACA;AACA;AACA;;AACA,QAAMI,QAAQ,GAAGH,IAAI,CAACI,KAAL,CAAW,CAAX,EAAc,EAAd,CAAjB;AACA,QAAMC,MAAM,GAAGF,QAAQ,CAACE,MAAxB;AACA,QAAMC,MAAM,GAAGL,MAAM,CAACM,KAAP,CAAaF,MAAb,CAAf,CAToC,CAUpC;;AACA,OAAK,IAAIG,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGH,MAApB,EAA4BG,CAAC,EAA7B,EAAiC;AAC/BF,IAAAA,MAAM,CAACD,MAAM,GAAGG,CAAT,GAAa,CAAd,CAAN,GAAyBL,QAAQ,CAACK,CAAD,CAAjC;AACD;;AAED,SAAOF,MAAP;AACD,CAhBD;;AAiBAR,MAAM,CAACW,IAAP,GAAc,IAAd,C,CAAmB;;AAEnB,MAAMC,cAAc,GAAG;AACrBZ,EAAAA,MAAM,EAAEA;AADa,CAAvB;;AAIA,MAAMa,UAAN,SAAyBjB,GAAzB,CAA6B;AAC3BkB,EAAAA,WAAW,CAAEC,KAAF,EAASC,OAAT,EAAkB;AAC3BA,IAAAA,OAAO,GAAGjB,MAAM,CAAC,EAAD,EAAKa,cAAL,EAAqBI,OAArB,CAAhB;AAEA,UAAMD,KAAN,EAAaC,OAAb;AAEA,SAAKC,OAAL,GAAenB,MAAM,CAACkB,OAAD,CAArB;AACD;;AAED,QAAME,GAAN,CAAWC,IAAX,EAAiBlB,KAAjB,EAAwB;AACtB,UAAM,KAAKgB,OAAL,CAAaC,GAAb,CAAiBC,IAAjB,EAAuBlB,KAAvB,CAAN;AACD;;AAEDmB,EAAAA,GAAG,CAAED,IAAF,EAAQ;AACT,WAAO,KAAKF,OAAL,CAAaG,GAAb,CAAiBD,IAAjB,CAAP;AACD;;AAEDE,EAAAA,UAAU,GAAI;AACZ,WAAO,KAAKJ,OAAL,CAAaK,SAAb,EAAP;AACD;;AAEDC,EAAAA,mBAAmB,GAAI;AACrB,WAAO,KAAKN,OAAL,CAAaO,aAAb,EAAP;AACD;;AAEDC,EAAAA,SAAS,GAAI;AACX,WAAO,KAAKR,OAAL,CAAaQ,SAAb,EAAP;AACD;;AAED,SAAQC,eAAR,GAA2B;AACzB,eAAW,MAAM;AAAEC,MAAAA,GAAF;AAAO1B,MAAAA;AAAP,KAAjB,IAAmC,KAAKgB,OAAL,CAAaW,cAAb,EAAnC,EAAkE;AAChE,YAAM;AACJD,QAAAA,GADI;AAEJE,QAAAA,KAAK,EAAE5B;AAFH,OAAN;AAID;AACF;;AAED,SAAQ6B,KAAR,CAAeC,IAAf,EAAqBC,IAArB,EAA2B;AACzB,eAAW,MAAMC,KAAjB,IAA0BH,KAAK,CAACC,IAAD,EAAO,KAAKd,OAAZ,EAAqBe,IAArB,EAA2B,KAAKhB,OAAhC,CAA/B,EAAyE;AACvE,YAAMiB,KAAN;AACD;AACF;;AA1C0B;;AA6C7BC,MAAM,CAACC,OAAP,GAAiBtB,UAAjB;AAEAqB,MAAM,CAACC,OAAP,CAAenC,MAAf,GAAwBA,MAAxB;;AAEA,gBAAiB8B,KAAjB,CAAwBC,IAAxB,EAA8BK,MAA9B,EAAsCJ,IAAtC,EAA4ChB,OAA5C,EAAqD;AACnD,QAAMqB,QAAQ,GAAGD,MAAM,CAACE,SAAxB;AACA,QAAMC,KAAK,GAAG,EAAd;;AAEA,OAAK,IAAI7B,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG2B,QAAQ,CAAC9B,MAA7B,EAAqCG,CAAC,EAAtC,EAA0C;AACxC,UAAMmB,KAAK,GAAGQ,QAAQ,CAACjB,GAAT,CAAaV,CAAb,CAAd;;AAEA,QAAI,CAACmB,KAAL,EAAY;AACV;AACD;;AAED,UAAMW,WAAW,GAAG9B,CAAC,CAAC+B,QAAF,CAAW,EAAX,EAAeC,WAAf,GAA6BC,QAA7B,CAAsC,CAAtC,EAAyC,GAAzC,CAApB;;AAEA,QAAI7C,MAAM,CAAC8C,QAAP,CAAgBf,KAAhB,CAAJ,EAA4B;AAC1B,UAAIgB,KAAJ;;AAEA,iBAAW,MAAMC,QAAjB,IAA6B,MAAMhB,KAAK,CAAC,EAAD,EAAKD,KAAL,EAAYG,IAAZ,EAAkBhB,OAAlB,CAAxC,EAAoE;AAClE6B,QAAAA,KAAK,GAAGC,QAAR;AACD;;AAEDP,MAAAA,KAAK,CAACQ,IAAN,CAAW,IAAIxD,OAAJ,CAAYiD,WAAZ,EAAyBK,KAAK,CAACG,IAAN,CAAWC,IAApC,EAA0CJ,KAAK,CAACK,GAAhD,CAAX;AACD,KARD,MAQO,IAAI,OAAOrB,KAAK,CAAC5B,KAAN,CAAY6B,KAAnB,KAA6B,UAAjC,EAA6C;AAClD,YAAMqB,GAAG,GAAGtB,KAAK,CAAC5B,KAAlB;AACA,UAAImD,UAAJ;;AAEA,iBAAW,MAAMnB,KAAjB,IAA0BkB,GAAG,CAACrB,KAAJ,CAAUqB,GAAG,CAACpB,IAAd,EAAoBC,IAApB,CAA1B,EAAqD;AACnDoB,QAAAA,UAAU,GAAGnB,KAAb;AAEA,cAAMmB,UAAN;AACD;;AAED,YAAMC,KAAK,GAAGb,WAAW,GAAGX,KAAK,CAACF,GAAlC;AACAY,MAAAA,KAAK,CAACQ,IAAN,CAAW,IAAIxD,OAAJ,CAAY8D,KAAZ,EAAmBD,UAAU,CAACJ,IAAX,CAAgBC,IAAnC,EAAyCG,UAAU,CAACF,GAApD,CAAX;AACD,KAZM,MAYA;AACL,YAAMjD,KAAK,GAAG4B,KAAK,CAAC5B,KAApB;;AAEA,UAAI,CAACA,KAAK,CAAC+C,IAAX,EAAiB;AACf,YAAI/C,KAAK,CAACiD,GAAV,EAAe;AACbjD,UAAAA,KAAK,CAAC+C,IAAN,GAAa,MAAMhB,IAAI,CAACZ,GAAL,CAASnB,KAAK,CAACiD,GAAf,CAAnB;AACD,SAFD,MAEO;AACL;AACD;AACF;;AAED,YAAMG,KAAK,GAAGb,WAAW,GAAGX,KAAK,CAACF,GAAlC;AACA,YAAMsB,IAAI,GAAGhD,KAAK,CAAC+C,IAAN,CAAWzC,MAAX,IAAqBN,KAAK,CAAC+C,IAAN,CAAWC,IAAhC,IAAwChD,KAAK,CAAC+C,IAAN,CAAWM,IAAhE;AAEAf,MAAAA,KAAK,CAACQ,IAAN,CAAW,IAAIxD,OAAJ,CAAY8D,KAAZ,EAAmBJ,IAAnB,EAAyBhD,KAAK,CAACiD,GAA/B,CAAX;AACD;AACF,GAjDkD,CAmDnD;AACA;;;AACA,QAAMK,IAAI,GAAGpD,MAAM,CAACC,IAAP,CAAYiC,QAAQ,CAACmB,QAAT,GAAoBC,OAApB,EAAZ,CAAb;AACA,QAAMN,GAAG,GAAG,IAAIzD,MAAJ,CAAW,wBAAX,EAAqC6D,IAArC,CAAZ;AACAJ,EAAAA,GAAG,CAACO,MAAJ,GAAatB,MAAM,CAACuB,SAAP,EAAb;AACAR,EAAAA,GAAG,CAACS,QAAJ,GAAe5C,OAAO,CAAChB,MAAR,CAAeW,IAA9B;AAEA,QAAMqC,IAAI,GAAG,IAAIxD,OAAJ,CAAY2D,GAAG,CAACU,OAAJ,EAAZ,EAA2BtB,KAA3B,CAAb;AACA,QAAMW,GAAG,GAAG,MAAMrD,OAAO,CAACmD,IAAD,EAAOhB,IAAP,EAAahB,OAAb,CAAzB;AAEA,QAAM;AACJkC,IAAAA,GADI;AAEJF,IAAAA,IAFI;AAGJc,IAAAA,MAAM,EAAEX,GAHJ;AAIJpB,IAAAA;AAJI,GAAN;AAMD","sourcesContent":["'use strict'\n\nconst {\n  DAGLink,\n  DAGNode\n} = require('ipld-dag-pb')\nconst UnixFS = require('ipfs-unixfs')\nconst multihashing = require('multihashing-async')\nconst Dir = require('./dir')\nconst persist = require('./utils/persist')\nconst Bucket = require('hamt-sharding')\nconst extend = require('deep-extend')\n\nconst hashFn = async function (value) {\n  const hash = await multihashing(Buffer.from(value, 'utf8'), 'murmur3-128')\n\n  // Multihashing inserts preamble of 2 bytes. Remove it.\n  // Also, murmur3 outputs 128 bit but, accidently, IPFS Go's\n  // implementation only uses the first 64, so we must do the same\n  // for parity..\n  const justHash = hash.slice(2, 10)\n  const length = justHash.length\n  const result = Buffer.alloc(length)\n  // TODO: invert buffer because that's how Go impl does it\n  for (let i = 0; i < length; i++) {\n    result[length - i - 1] = justHash[i]\n  }\n\n  return result\n}\nhashFn.code = 0x22 // TODO: get this from multihashing-async?\n\nconst defaultOptions = {\n  hashFn: hashFn\n}\n\nclass DirSharded extends Dir {\n  constructor (props, options) {\n    options = extend({}, defaultOptions, options)\n\n    super(props, options)\n\n    this._bucket = Bucket(options)\n  }\n\n  async put (name, value) {\n    await this._bucket.put(name, value)\n  }\n\n  get (name) {\n    return this._bucket.get(name)\n  }\n\n  childCount () {\n    return this._bucket.leafCount()\n  }\n\n  directChildrenCount () {\n    return this._bucket.childrenCount()\n  }\n\n  onlyChild () {\n    return this._bucket.onlyChild()\n  }\n\n  async * eachChildSeries () {\n    for await (const { key, value } of this._bucket.eachLeafSeries()) {\n      yield {\n        key,\n        child: value\n      }\n    }\n  }\n\n  async * flush (path, ipld) {\n    for await (const entry of flush(path, this._bucket, ipld, this.options)) {\n      yield entry\n    }\n  }\n}\n\nmodule.exports = DirSharded\n\nmodule.exports.hashFn = hashFn\n\nasync function * flush (path, bucket, ipld, options) {\n  const children = bucket._children\n  const links = []\n\n  for (let i = 0; i < children.length; i++) {\n    const child = children.get(i)\n\n    if (!child) {\n      continue\n    }\n\n    const labelPrefix = i.toString(16).toUpperCase().padStart(2, '0')\n\n    if (Bucket.isBucket(child)) {\n      let shard\n\n      for await (const subShard of await flush('', child, ipld, options)) {\n        shard = subShard\n      }\n\n      links.push(new DAGLink(labelPrefix, shard.node.size, shard.cid))\n    } else if (typeof child.value.flush === 'function') {\n      const dir = child.value\n      let flushedDir\n\n      for await (const entry of dir.flush(dir.path, ipld)) {\n        flushedDir = entry\n\n        yield flushedDir\n      }\n\n      const label = labelPrefix + child.key\n      links.push(new DAGLink(label, flushedDir.node.size, flushedDir.cid))\n    } else {\n      const value = child.value\n\n      if (!value.node) {\n        if (value.cid) {\n          value.node = await ipld.get(value.cid)\n        } else {\n          continue\n        }\n      }\n\n      const label = labelPrefix + child.key\n      const size = value.node.length || value.node.size || value.node.Size\n\n      links.push(new DAGLink(label, size, value.cid))\n    }\n  }\n\n  // go-ipfs uses little endian, that's why we have to\n  // reverse the bit field before storing it\n  const data = Buffer.from(children.bitField().reverse())\n  const dir = new UnixFS('hamt-sharded-directory', data)\n  dir.fanout = bucket.tableSize()\n  dir.hashType = options.hashFn.code\n\n  const node = new DAGNode(dir.marshal(), links)\n  const cid = await persist(node, ipld, options)\n\n  yield {\n    cid,\n    node,\n    unixfs: dir,\n    path\n  }\n}\n"]},"metadata":{},"sourceType":"script"}