{"ast":null,"code":"'use strict';\n\nconst extractDataFromBlock = require('../../../utils/extract-data-from-block');\n\nconst validateOffsetAndLength = require('../../../utils/validate-offset-and-length');\n\nconst UnixFS = require('ipfs-unixfs');\n\nconst errCode = require('err-code');\n\nasync function* emitBytes(ipld, node, start, end, streamPosition = 0) {\n  // a `raw` node\n  if (Buffer.isBuffer(node)) {\n    const buf = extractDataFromBlock(node, streamPosition, start, end);\n\n    if (buf.length) {\n      yield buf;\n    }\n\n    streamPosition += buf.length;\n    return streamPosition;\n  }\n\n  let file;\n\n  try {\n    file = UnixFS.unmarshal(node.Data);\n  } catch (err) {\n    throw errCode(err, 'ERR_NOT_UNIXFS');\n  } // might be a unixfs `raw` node or have data on intermediate nodes\n\n\n  const nodeHasData = Boolean(file.data && file.data.length);\n\n  if (nodeHasData) {\n    const buf = extractDataFromBlock(file.data, streamPosition, start, end);\n\n    if (buf.length) {\n      yield buf;\n    }\n\n    streamPosition += file.data.length;\n  }\n\n  let childStart = streamPosition; // work out which child nodes contain the requested data\n\n  for (let i = 0; i < node.Links.length; i++) {\n    const childLink = node.Links[i];\n    const childEnd = streamPosition + file.blockSizes[i];\n\n    if (start >= childStart && start < childEnd || // child has offset byte\n    end > childStart && end <= childEnd || // child has end byte\n    start < childStart && end > childEnd) {\n      // child is between offset and end bytes\n      const child = await ipld.get(childLink.Hash);\n\n      for await (const buf of emitBytes(ipld, child, start, end, streamPosition)) {\n        streamPosition += buf.length;\n        yield buf;\n      }\n    }\n\n    streamPosition = childEnd;\n    childStart = childEnd + 1;\n  }\n}\n\nconst fileContent = (cid, node, unixfs, path, resolve, depth, ipld) => {\n  return (options = {}) => {\n    const fileSize = unixfs.fileSize();\n    const {\n      offset,\n      length\n    } = validateOffsetAndLength(fileSize, options.offset, options.length);\n    const start = offset;\n    const end = offset + length;\n    return emitBytes(ipld, node, start, end);\n  };\n};\n\nmodule.exports = fileContent;","map":{"version":3,"sources":["/home/dekan/Projects/raid-guild/dao-badges-web/node_modules/ipfs-unixfs-exporter/src/resolvers/unixfs-v1/content/file.js"],"names":["extractDataFromBlock","require","validateOffsetAndLength","UnixFS","errCode","emitBytes","ipld","node","start","end","streamPosition","Buffer","isBuffer","buf","length","file","unmarshal","Data","err","nodeHasData","Boolean","data","childStart","i","Links","childLink","childEnd","blockSizes","child","get","Hash","fileContent","cid","unixfs","path","resolve","depth","options","fileSize","offset","module","exports"],"mappings":"AAAA;;AAEA,MAAMA,oBAAoB,GAAGC,OAAO,CAAC,wCAAD,CAApC;;AACA,MAAMC,uBAAuB,GAAGD,OAAO,CAAC,2CAAD,CAAvC;;AACA,MAAME,MAAM,GAAGF,OAAO,CAAC,aAAD,CAAtB;;AACA,MAAMG,OAAO,GAAGH,OAAO,CAAC,UAAD,CAAvB;;AAEA,gBAAiBI,SAAjB,CAA4BC,IAA5B,EAAkCC,IAAlC,EAAwCC,KAAxC,EAA+CC,GAA/C,EAAoDC,cAAc,GAAG,CAArE,EAAwE;AACtE;AACA,MAAIC,MAAM,CAACC,QAAP,CAAgBL,IAAhB,CAAJ,EAA2B;AACzB,UAAMM,GAAG,GAAGb,oBAAoB,CAACO,IAAD,EAAOG,cAAP,EAAuBF,KAAvB,EAA8BC,GAA9B,CAAhC;;AAEA,QAAII,GAAG,CAACC,MAAR,EAAgB;AACd,YAAMD,GAAN;AACD;;AAEDH,IAAAA,cAAc,IAAIG,GAAG,CAACC,MAAtB;AAEA,WAAOJ,cAAP;AACD;;AAED,MAAIK,IAAJ;;AAEA,MAAI;AACFA,IAAAA,IAAI,GAAGZ,MAAM,CAACa,SAAP,CAAiBT,IAAI,CAACU,IAAtB,CAAP;AACD,GAFD,CAEE,OAAOC,GAAP,EAAY;AACZ,UAAMd,OAAO,CAACc,GAAD,EAAM,gBAAN,CAAb;AACD,GApBqE,CAsBtE;;;AACA,QAAMC,WAAW,GAAGC,OAAO,CAACL,IAAI,CAACM,IAAL,IAAaN,IAAI,CAACM,IAAL,CAAUP,MAAxB,CAA3B;;AAEA,MAAIK,WAAJ,EAAiB;AACf,UAAMN,GAAG,GAAGb,oBAAoB,CAACe,IAAI,CAACM,IAAN,EAAYX,cAAZ,EAA4BF,KAA5B,EAAmCC,GAAnC,CAAhC;;AAEA,QAAII,GAAG,CAACC,MAAR,EAAgB;AACd,YAAMD,GAAN;AACD;;AAEDH,IAAAA,cAAc,IAAIK,IAAI,CAACM,IAAL,CAAUP,MAA5B;AACD;;AAED,MAAIQ,UAAU,GAAGZ,cAAjB,CAnCsE,CAqCtE;;AACA,OAAK,IAAIa,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGhB,IAAI,CAACiB,KAAL,CAAWV,MAA/B,EAAuCS,CAAC,EAAxC,EAA4C;AAC1C,UAAME,SAAS,GAAGlB,IAAI,CAACiB,KAAL,CAAWD,CAAX,CAAlB;AACA,UAAMG,QAAQ,GAAGhB,cAAc,GAAGK,IAAI,CAACY,UAAL,CAAgBJ,CAAhB,CAAlC;;AAEA,QAAKf,KAAK,IAAIc,UAAT,IAAuBd,KAAK,GAAGkB,QAAhC,IAA6C;AAC5CjB,IAAAA,GAAG,GAAGa,UAAN,IAAoBb,GAAG,IAAIiB,QAD5B,IACyC;AACxClB,IAAAA,KAAK,GAAGc,UAAR,IAAsBb,GAAG,GAAGiB,QAFjC,EAE4C;AAAE;AAC5C,YAAME,KAAK,GAAG,MAAMtB,IAAI,CAACuB,GAAL,CAASJ,SAAS,CAACK,IAAnB,CAApB;;AAEA,iBAAW,MAAMjB,GAAjB,IAAwBR,SAAS,CAACC,IAAD,EAAOsB,KAAP,EAAcpB,KAAd,EAAqBC,GAArB,EAA0BC,cAA1B,CAAjC,EAA4E;AAC1EA,QAAAA,cAAc,IAAIG,GAAG,CAACC,MAAtB;AAEA,cAAMD,GAAN;AACD;AACF;;AAEDH,IAAAA,cAAc,GAAGgB,QAAjB;AACAJ,IAAAA,UAAU,GAAGI,QAAQ,GAAG,CAAxB;AACD;AACF;;AAED,MAAMK,WAAW,GAAG,CAACC,GAAD,EAAMzB,IAAN,EAAY0B,MAAZ,EAAoBC,IAApB,EAA0BC,OAA1B,EAAmCC,KAAnC,EAA0C9B,IAA1C,KAAmD;AACrE,SAAO,CAAC+B,OAAO,GAAG,EAAX,KAAkB;AACvB,UAAMC,QAAQ,GAAGL,MAAM,CAACK,QAAP,EAAjB;AAEA,UAAM;AACJC,MAAAA,MADI;AAEJzB,MAAAA;AAFI,QAGFZ,uBAAuB,CAACoC,QAAD,EAAWD,OAAO,CAACE,MAAnB,EAA2BF,OAAO,CAACvB,MAAnC,CAH3B;AAKA,UAAMN,KAAK,GAAG+B,MAAd;AACA,UAAM9B,GAAG,GAAG8B,MAAM,GAAGzB,MAArB;AAEA,WAAOT,SAAS,CAACC,IAAD,EAAOC,IAAP,EAAaC,KAAb,EAAoBC,GAApB,CAAhB;AACD,GAZD;AAaD,CAdD;;AAgBA+B,MAAM,CAACC,OAAP,GAAiBV,WAAjB","sourcesContent":["'use strict'\n\nconst extractDataFromBlock = require('../../../utils/extract-data-from-block')\nconst validateOffsetAndLength = require('../../../utils/validate-offset-and-length')\nconst UnixFS = require('ipfs-unixfs')\nconst errCode = require('err-code')\n\nasync function * emitBytes (ipld, node, start, end, streamPosition = 0) {\n  // a `raw` node\n  if (Buffer.isBuffer(node)) {\n    const buf = extractDataFromBlock(node, streamPosition, start, end)\n\n    if (buf.length) {\n      yield buf\n    }\n\n    streamPosition += buf.length\n\n    return streamPosition\n  }\n\n  let file\n\n  try {\n    file = UnixFS.unmarshal(node.Data)\n  } catch (err) {\n    throw errCode(err, 'ERR_NOT_UNIXFS')\n  }\n\n  // might be a unixfs `raw` node or have data on intermediate nodes\n  const nodeHasData = Boolean(file.data && file.data.length)\n\n  if (nodeHasData) {\n    const buf = extractDataFromBlock(file.data, streamPosition, start, end)\n\n    if (buf.length) {\n      yield buf\n    }\n\n    streamPosition += file.data.length\n  }\n\n  let childStart = streamPosition\n\n  // work out which child nodes contain the requested data\n  for (let i = 0; i < node.Links.length; i++) {\n    const childLink = node.Links[i]\n    const childEnd = streamPosition + file.blockSizes[i]\n\n    if ((start >= childStart && start < childEnd) || // child has offset byte\n        (end > childStart && end <= childEnd) || // child has end byte\n        (start < childStart && end > childEnd)) { // child is between offset and end bytes\n      const child = await ipld.get(childLink.Hash)\n\n      for await (const buf of emitBytes(ipld, child, start, end, streamPosition)) {\n        streamPosition += buf.length\n\n        yield buf\n      }\n    }\n\n    streamPosition = childEnd\n    childStart = childEnd + 1\n  }\n}\n\nconst fileContent = (cid, node, unixfs, path, resolve, depth, ipld) => {\n  return (options = {}) => {\n    const fileSize = unixfs.fileSize()\n\n    const {\n      offset,\n      length\n    } = validateOffsetAndLength(fileSize, options.offset, options.length)\n\n    const start = offset\n    const end = offset + length\n\n    return emitBytes(ipld, node, start, end)\n  }\n}\n\nmodule.exports = fileContent\n"]},"metadata":{},"sourceType":"script"}