{"ast":null,"code":"'use strict';\n\nconst log = require('debug')('ipfs:mfs:write');\n\nconst importer = require('ipfs-unixfs-importer');\n\nconst stat = require('./stat');\n\nconst mkdir = require('./mkdir');\n\nconst addLink = require('./utils/add-link');\n\nconst applyDefaultOptions = require('./utils/apply-default-options');\n\nconst createLock = require('./utils/create-lock');\n\nconst toAsyncIterator = require('./utils/to-async-iterator');\n\nconst toMfsPath = require('./utils/to-mfs-path');\n\nconst toPathComponents = require('./utils/to-path-components');\n\nconst toTrail = require('./utils/to-trail');\n\nconst updateTree = require('./utils/update-tree');\n\nconst updateMfsRoot = require('./utils/update-mfs-root');\n\nconst errCode = require('err-code');\n\nconst {\n  MAX_CHUNK_SIZE\n} = require('./utils/constants');\n\nconst last = require('async-iterator-last');\n\nconst defaultOptions = {\n  offset: 0,\n  // the offset in the file to begin writing\n  length: undefined,\n  // how many bytes from the incoming buffer to write\n  create: false,\n  // whether to create the file if it does not exist\n  truncate: false,\n  // whether to truncate the file first\n  rawLeaves: false,\n  reduceSingleLeafToSelf: false,\n  cidVersion: 0,\n  hashAlg: 'sha2-256',\n  format: 'dag-pb',\n  parents: false,\n  // whether to create intermediate directories if they do not exist\n  progress: () => {},\n  strategy: 'trickle',\n  flush: true,\n  leafType: 'raw',\n  shardSplitThreshold: 1000\n};\n\nmodule.exports = context => {\n  return async function mfsWrite(path, content, options) {\n    log('Hello world, writing', path, content, options);\n    options = applyDefaultOptions(options, defaultOptions);\n    let source, destination, parent;\n    log('Reading source, destination and parent');\n    await createLock().readLock(async () => {\n      source = await toAsyncIterator(content, options);\n      destination = await toMfsPath(context, path);\n      parent = await toMfsPath(context, destination.mfsDirectory);\n    })();\n    log('Read source, destination and parent');\n\n    if (!options.parents && !parent.exists) {\n      throw errCode(new Error('directory does not exist'), 'ERR_NO_EXIST');\n    }\n\n    if (!options.create && !destination.exists) {\n      throw errCode(new Error('file does not exist'), 'ERR_NO_EXIST');\n    }\n\n    return updateOrImport(context, path, source, destination, options);\n  };\n};\n\nconst updateOrImport = async (context, path, source, destination, options) => {\n  const child = await write(context, source, destination, options); // The slow bit is done, now add or replace the DAGLink in the containing directory\n  // re-reading the path to the containing folder in case it has changed in the interim\n\n  await createLock().writeLock(async () => {\n    const pathComponents = toPathComponents(path);\n    const fileName = pathComponents.pop();\n    let parentExists = false;\n\n    try {\n      await stat(context)(`/${pathComponents.join('/')}`, options);\n      parentExists = true;\n    } catch (err) {\n      if (err.code !== 'ERR_NOT_FOUND') {\n        throw err;\n      }\n    }\n\n    if (!parentExists) {\n      await mkdir(context)(`/${pathComponents.join('/')}`, options);\n    } // get an updated mfs path in case the root changed while we were writing\n\n\n    const updatedPath = await toMfsPath(context, path);\n    const trail = await toTrail(context, updatedPath.mfsDirectory, options);\n    const parent = trail[trail.length - 1];\n\n    if (!parent.type.includes('directory')) {\n      throw errCode(new Error(`cannot write to ${parent.name}: Not a directory`), 'ERR_NOT_A_DIRECTORY');\n    }\n\n    const parentNode = await context.ipld.get(parent.cid);\n    const result = await addLink(context, {\n      parent: parentNode,\n      name: fileName,\n      cid: child.cid,\n      size: child.size,\n      flush: options.flush,\n      shardSplitThreshold: options.shardSplitThreshold,\n      format: options.format,\n      hashAlg: options.hashAlg,\n      cidVersion: options.cidVersion\n    });\n    parent.cid = result.cid; // update the tree with the new child\n\n    const newRootCid = await updateTree(context, trail, options); // Update the MFS record with the new CID for the root of the tree\n\n    await updateMfsRoot(context, newRootCid);\n  })();\n};\n\nconst write = async (context, source, destination, options) => {\n  if (destination.exists) {\n    log(`Overwriting file ${destination.cid} offset ${options.offset} length ${options.length}`);\n  } else {\n    log(`Writing file offset ${options.offset} length ${options.length}`);\n  }\n\n  const sources = []; // pad start of file if necessary\n\n  if (options.offset > 0) {\n    if (destination.unixfs && destination.unixfs.fileSize() > options.offset) {\n      log(`Writing first ${options.offset} bytes of original file`);\n      sources.push(() => {\n        return destination.content({\n          offset: 0,\n          length: options.offset\n        });\n      });\n    } else {\n      log(`Writing zeros for first ${options.offset} bytes`);\n      sources.push(asyncZeroes(options.offset));\n    }\n  }\n\n  sources.push(limitAsyncStreamBytes(source, options.length));\n  const content = countBytesStreamed(catAsyncInterators(sources), bytesWritten => {\n    if (destination.unixfs && !options.truncate) {\n      // if we've done reading from the new source and we are not going\n      // to truncate the file, add the end of the existing file to the output\n      const fileSize = destination.unixfs.fileSize();\n\n      if (fileSize > bytesWritten) {\n        log(`Writing last ${fileSize - bytesWritten} of ${fileSize} bytes from original file starting at offset ${bytesWritten}`);\n        return destination.content({\n          offset: bytesWritten\n        });\n      } else {\n        log('Not writing last bytes from original file');\n      }\n    }\n\n    return {\n      [Symbol.asyncIterator]: async function* () {}\n    };\n  });\n  const result = await last(importer([{\n    content: content\n  }], context.ipld, {\n    progress: options.progress,\n    hashAlg: options.hashAlg,\n    cidVersion: options.cidVersion,\n    strategy: options.strategy,\n    rawLeaves: options.rawLeaves,\n    reduceSingleLeafToSelf: options.reduceSingleLeafToSelf,\n    leafType: options.leafType\n  }));\n  log(`Wrote ${result.cid}`);\n  return {\n    cid: result.cid,\n    size: result.size\n  };\n};\n\nconst limitAsyncStreamBytes = (stream, limit) => {\n  return async function* _limitAsyncStreamBytes() {\n    let emitted = 0;\n\n    for await (const buf of stream) {\n      emitted += buf.length;\n\n      if (emitted > limit) {\n        yield buf.slice(0, limit - emitted);\n        return;\n      }\n\n      yield buf;\n    }\n  };\n};\n\nconst asyncZeroes = (count, chunkSize = MAX_CHUNK_SIZE) => {\n  const buf = Buffer.alloc(chunkSize, 0);\n  const stream = {\n    [Symbol.asyncIterator]: function* _asyncZeroes() {\n      while (true) {\n        yield buf.slice();\n      }\n    }\n  };\n  return limitAsyncStreamBytes(stream, count);\n};\n\nconst catAsyncInterators = async function* (sources) {\n  for (let i = 0; i < sources.length; i++) {\n    for await (const buf of sources[i]()) {\n      yield buf;\n    }\n  }\n};\n\nconst countBytesStreamed = async function* (source, notify) {\n  let wrote = 0;\n\n  for await (const buf of source) {\n    wrote += buf.length;\n    yield buf;\n  }\n\n  for await (const buf of notify(wrote)) {\n    wrote += buf.length;\n    yield buf;\n  }\n};","map":{"version":3,"sources":["/home/dekan/Projects/raid-guild/dao-badges-web/node_modules/ipfs-mfs/src/core/write.js"],"names":["log","require","importer","stat","mkdir","addLink","applyDefaultOptions","createLock","toAsyncIterator","toMfsPath","toPathComponents","toTrail","updateTree","updateMfsRoot","errCode","MAX_CHUNK_SIZE","last","defaultOptions","offset","length","undefined","create","truncate","rawLeaves","reduceSingleLeafToSelf","cidVersion","hashAlg","format","parents","progress","strategy","flush","leafType","shardSplitThreshold","module","exports","context","mfsWrite","path","content","options","source","destination","parent","readLock","mfsDirectory","exists","Error","updateOrImport","child","write","writeLock","pathComponents","fileName","pop","parentExists","join","err","code","updatedPath","trail","type","includes","name","parentNode","ipld","get","cid","result","size","newRootCid","sources","unixfs","fileSize","push","asyncZeroes","limitAsyncStreamBytes","countBytesStreamed","catAsyncInterators","bytesWritten","Symbol","asyncIterator","stream","limit","_limitAsyncStreamBytes","emitted","buf","slice","count","chunkSize","Buffer","alloc","_asyncZeroes","i","notify","wrote"],"mappings":"AAAA;;AAEA,MAAMA,GAAG,GAAGC,OAAO,CAAC,OAAD,CAAP,CAAiB,gBAAjB,CAAZ;;AACA,MAAMC,QAAQ,GAAGD,OAAO,CAAC,sBAAD,CAAxB;;AACA,MAAME,IAAI,GAAGF,OAAO,CAAC,QAAD,CAApB;;AACA,MAAMG,KAAK,GAAGH,OAAO,CAAC,SAAD,CAArB;;AACA,MAAMI,OAAO,GAAGJ,OAAO,CAAC,kBAAD,CAAvB;;AACA,MAAMK,mBAAmB,GAAGL,OAAO,CAAC,+BAAD,CAAnC;;AACA,MAAMM,UAAU,GAAGN,OAAO,CAAC,qBAAD,CAA1B;;AACA,MAAMO,eAAe,GAAGP,OAAO,CAAC,2BAAD,CAA/B;;AACA,MAAMQ,SAAS,GAAGR,OAAO,CAAC,qBAAD,CAAzB;;AACA,MAAMS,gBAAgB,GAAGT,OAAO,CAAC,4BAAD,CAAhC;;AACA,MAAMU,OAAO,GAAGV,OAAO,CAAC,kBAAD,CAAvB;;AACA,MAAMW,UAAU,GAAGX,OAAO,CAAC,qBAAD,CAA1B;;AACA,MAAMY,aAAa,GAAGZ,OAAO,CAAC,yBAAD,CAA7B;;AACA,MAAMa,OAAO,GAAGb,OAAO,CAAC,UAAD,CAAvB;;AACA,MAAM;AACJc,EAAAA;AADI,IAEFd,OAAO,CAAC,mBAAD,CAFX;;AAGA,MAAMe,IAAI,GAAGf,OAAO,CAAC,qBAAD,CAApB;;AAEA,MAAMgB,cAAc,GAAG;AACrBC,EAAAA,MAAM,EAAE,CADa;AACV;AACXC,EAAAA,MAAM,EAAEC,SAFa;AAEF;AACnBC,EAAAA,MAAM,EAAE,KAHa;AAGN;AACfC,EAAAA,QAAQ,EAAE,KAJW;AAIJ;AACjBC,EAAAA,SAAS,EAAE,KALU;AAMrBC,EAAAA,sBAAsB,EAAE,KANH;AAOrBC,EAAAA,UAAU,EAAE,CAPS;AAQrBC,EAAAA,OAAO,EAAE,UARY;AASrBC,EAAAA,MAAM,EAAE,QATa;AAUrBC,EAAAA,OAAO,EAAE,KAVY;AAUL;AAChBC,EAAAA,QAAQ,EAAE,MAAM,CAAE,CAXG;AAYrBC,EAAAA,QAAQ,EAAE,SAZW;AAarBC,EAAAA,KAAK,EAAE,IAbc;AAcrBC,EAAAA,QAAQ,EAAE,KAdW;AAerBC,EAAAA,mBAAmB,EAAE;AAfA,CAAvB;;AAkBAC,MAAM,CAACC,OAAP,GAAkBC,OAAD,IAAa;AAC5B,SAAO,eAAeC,QAAf,CAAyBC,IAAzB,EAA+BC,OAA/B,EAAwCC,OAAxC,EAAiD;AACtDxC,IAAAA,GAAG,CAAC,sBAAD,EAAyBsC,IAAzB,EAA+BC,OAA/B,EAAwCC,OAAxC,CAAH;AACAA,IAAAA,OAAO,GAAGlC,mBAAmB,CAACkC,OAAD,EAAUvB,cAAV,CAA7B;AAEA,QAAIwB,MAAJ,EAAYC,WAAZ,EAAyBC,MAAzB;AACA3C,IAAAA,GAAG,CAAC,wCAAD,CAAH;AACA,UAAMO,UAAU,GAAGqC,QAAb,CAAsB,YAAY;AACtCH,MAAAA,MAAM,GAAG,MAAMjC,eAAe,CAAC+B,OAAD,EAAUC,OAAV,CAA9B;AACAE,MAAAA,WAAW,GAAG,MAAMjC,SAAS,CAAC2B,OAAD,EAAUE,IAAV,CAA7B;AACAK,MAAAA,MAAM,GAAG,MAAMlC,SAAS,CAAC2B,OAAD,EAAUM,WAAW,CAACG,YAAtB,CAAxB;AACD,KAJK,GAAN;AAKA7C,IAAAA,GAAG,CAAC,qCAAD,CAAH;;AACA,QAAI,CAACwC,OAAO,CAACZ,OAAT,IAAoB,CAACe,MAAM,CAACG,MAAhC,EAAwC;AACtC,YAAMhC,OAAO,CAAC,IAAIiC,KAAJ,CAAU,0BAAV,CAAD,EAAwC,cAAxC,CAAb;AACD;;AAED,QAAI,CAACP,OAAO,CAACnB,MAAT,IAAmB,CAACqB,WAAW,CAACI,MAApC,EAA4C;AAC1C,YAAMhC,OAAO,CAAC,IAAIiC,KAAJ,CAAU,qBAAV,CAAD,EAAmC,cAAnC,CAAb;AACD;;AAED,WAAOC,cAAc,CAACZ,OAAD,EAAUE,IAAV,EAAgBG,MAAhB,EAAwBC,WAAxB,EAAqCF,OAArC,CAArB;AACD,GArBD;AAsBD,CAvBD;;AAyBA,MAAMQ,cAAc,GAAG,OAAOZ,OAAP,EAAgBE,IAAhB,EAAsBG,MAAtB,EAA8BC,WAA9B,EAA2CF,OAA3C,KAAuD;AAC5E,QAAMS,KAAK,GAAG,MAAMC,KAAK,CAACd,OAAD,EAAUK,MAAV,EAAkBC,WAAlB,EAA+BF,OAA/B,CAAzB,CAD4E,CAG5E;AACA;;AACA,QAAMjC,UAAU,GAAG4C,SAAb,CAAuB,YAAY;AACvC,UAAMC,cAAc,GAAG1C,gBAAgB,CAAC4B,IAAD,CAAvC;AACA,UAAMe,QAAQ,GAAGD,cAAc,CAACE,GAAf,EAAjB;AACA,QAAIC,YAAY,GAAG,KAAnB;;AAEA,QAAI;AACF,YAAMpD,IAAI,CAACiC,OAAD,CAAJ,CAAe,IAAGgB,cAAc,CAACI,IAAf,CAAoB,GAApB,CAAyB,EAA3C,EAA8ChB,OAA9C,CAAN;AACAe,MAAAA,YAAY,GAAG,IAAf;AACD,KAHD,CAGE,OAAOE,GAAP,EAAY;AACZ,UAAIA,GAAG,CAACC,IAAJ,KAAa,eAAjB,EAAkC;AAChC,cAAMD,GAAN;AACD;AACF;;AAED,QAAI,CAACF,YAAL,EAAmB;AACjB,YAAMnD,KAAK,CAACgC,OAAD,CAAL,CAAgB,IAAGgB,cAAc,CAACI,IAAf,CAAoB,GAApB,CAAyB,EAA5C,EAA+ChB,OAA/C,CAAN;AACD,KAhBsC,CAkBvC;;;AACA,UAAMmB,WAAW,GAAG,MAAMlD,SAAS,CAAC2B,OAAD,EAAUE,IAAV,CAAnC;AACA,UAAMsB,KAAK,GAAG,MAAMjD,OAAO,CAACyB,OAAD,EAAUuB,WAAW,CAACd,YAAtB,EAAoCL,OAApC,CAA3B;AACA,UAAMG,MAAM,GAAGiB,KAAK,CAACA,KAAK,CAACzC,MAAN,GAAe,CAAhB,CAApB;;AAEA,QAAI,CAACwB,MAAM,CAACkB,IAAP,CAAYC,QAAZ,CAAqB,WAArB,CAAL,EAAwC;AACtC,YAAMhD,OAAO,CAAC,IAAIiC,KAAJ,CAAW,mBAAkBJ,MAAM,CAACoB,IAAK,mBAAzC,CAAD,EAA+D,qBAA/D,CAAb;AACD;;AAED,UAAMC,UAAU,GAAG,MAAM5B,OAAO,CAAC6B,IAAR,CAAaC,GAAb,CAAiBvB,MAAM,CAACwB,GAAxB,CAAzB;AAEA,UAAMC,MAAM,GAAG,MAAM/D,OAAO,CAAC+B,OAAD,EAAU;AACpCO,MAAAA,MAAM,EAAEqB,UAD4B;AAEpCD,MAAAA,IAAI,EAAEV,QAF8B;AAGpCc,MAAAA,GAAG,EAAElB,KAAK,CAACkB,GAHyB;AAIpCE,MAAAA,IAAI,EAAEpB,KAAK,CAACoB,IAJwB;AAKpCtC,MAAAA,KAAK,EAAES,OAAO,CAACT,KALqB;AAMpCE,MAAAA,mBAAmB,EAAEO,OAAO,CAACP,mBANO;AAOpCN,MAAAA,MAAM,EAAEa,OAAO,CAACb,MAPoB;AAQpCD,MAAAA,OAAO,EAAEc,OAAO,CAACd,OARmB;AASpCD,MAAAA,UAAU,EAAEe,OAAO,CAACf;AATgB,KAAV,CAA5B;AAYAkB,IAAAA,MAAM,CAACwB,GAAP,GAAaC,MAAM,CAACD,GAApB,CAzCuC,CA2CvC;;AACA,UAAMG,UAAU,GAAG,MAAM1D,UAAU,CAACwB,OAAD,EAAUwB,KAAV,EAAiBpB,OAAjB,CAAnC,CA5CuC,CA8CvC;;AACA,UAAM3B,aAAa,CAACuB,OAAD,EAAUkC,UAAV,CAAnB;AACD,GAhDK,GAAN;AAiDD,CAtDD;;AAwDA,MAAMpB,KAAK,GAAG,OAAOd,OAAP,EAAgBK,MAAhB,EAAwBC,WAAxB,EAAqCF,OAArC,KAAiD;AAC7D,MAAIE,WAAW,CAACI,MAAhB,EAAwB;AACtB9C,IAAAA,GAAG,CAAE,oBAAmB0C,WAAW,CAACyB,GAAI,WAAU3B,OAAO,CAACtB,MAAO,WAAUsB,OAAO,CAACrB,MAAO,EAAvF,CAAH;AACD,GAFD,MAEO;AACLnB,IAAAA,GAAG,CAAE,uBAAsBwC,OAAO,CAACtB,MAAO,WAAUsB,OAAO,CAACrB,MAAO,EAAhE,CAAH;AACD;;AAED,QAAMoD,OAAO,GAAG,EAAhB,CAP6D,CAS7D;;AACA,MAAI/B,OAAO,CAACtB,MAAR,GAAiB,CAArB,EAAwB;AACtB,QAAIwB,WAAW,CAAC8B,MAAZ,IAAsB9B,WAAW,CAAC8B,MAAZ,CAAmBC,QAAnB,KAAgCjC,OAAO,CAACtB,MAAlE,EAA0E;AACxElB,MAAAA,GAAG,CAAE,iBAAgBwC,OAAO,CAACtB,MAAO,yBAAjC,CAAH;AAEAqD,MAAAA,OAAO,CAACG,IAAR,CACE,MAAM;AACJ,eAAOhC,WAAW,CAACH,OAAZ,CAAoB;AACzBrB,UAAAA,MAAM,EAAE,CADiB;AAEzBC,UAAAA,MAAM,EAAEqB,OAAO,CAACtB;AAFS,SAApB,CAAP;AAID,OANH;AAQD,KAXD,MAWO;AACLlB,MAAAA,GAAG,CAAE,2BAA0BwC,OAAO,CAACtB,MAAO,QAA3C,CAAH;AACAqD,MAAAA,OAAO,CAACG,IAAR,CACEC,WAAW,CAACnC,OAAO,CAACtB,MAAT,CADb;AAGD;AACF;;AAEDqD,EAAAA,OAAO,CAACG,IAAR,CACEE,qBAAqB,CAACnC,MAAD,EAASD,OAAO,CAACrB,MAAjB,CADvB;AAIA,QAAMoB,OAAO,GAAGsC,kBAAkB,CAACC,kBAAkB,CAACP,OAAD,CAAnB,EAA+BQ,YAAD,IAAkB;AAChF,QAAIrC,WAAW,CAAC8B,MAAZ,IAAsB,CAAChC,OAAO,CAAClB,QAAnC,EAA6C;AAC3C;AACA;AACA,YAAMmD,QAAQ,GAAG/B,WAAW,CAAC8B,MAAZ,CAAmBC,QAAnB,EAAjB;;AAEA,UAAIA,QAAQ,GAAGM,YAAf,EAA6B;AAC3B/E,QAAAA,GAAG,CAAE,gBAAeyE,QAAQ,GAAGM,YAAa,OAAMN,QAAS,gDAA+CM,YAAa,EAApH,CAAH;AAEA,eAAOrC,WAAW,CAACH,OAAZ,CAAoB;AACzBrB,UAAAA,MAAM,EAAE6D;AADiB,SAApB,CAAP;AAGD,OAND,MAMO;AACL/E,QAAAA,GAAG,CAAC,2CAAD,CAAH;AACD;AACF;;AAED,WAAO;AACL,OAACgF,MAAM,CAACC,aAAR,GAAwB,mBAAoB,CAAE;AADzC,KAAP;AAGD,GApBiC,CAAlC;AAsBA,QAAMb,MAAM,GAAG,MAAMpD,IAAI,CAACd,QAAQ,CAAC,CAAC;AAClCqC,IAAAA,OAAO,EAAEA;AADyB,GAAD,CAAD,EAE9BH,OAAO,CAAC6B,IAFsB,EAEhB;AAChBpC,IAAAA,QAAQ,EAAEW,OAAO,CAACX,QADF;AAEhBH,IAAAA,OAAO,EAAEc,OAAO,CAACd,OAFD;AAGhBD,IAAAA,UAAU,EAAEe,OAAO,CAACf,UAHJ;AAIhBK,IAAAA,QAAQ,EAAEU,OAAO,CAACV,QAJF;AAKhBP,IAAAA,SAAS,EAAEiB,OAAO,CAACjB,SALH;AAMhBC,IAAAA,sBAAsB,EAAEgB,OAAO,CAAChB,sBANhB;AAOhBQ,IAAAA,QAAQ,EAAEQ,OAAO,CAACR;AAPF,GAFgB,CAAT,CAAzB;AAYAhC,EAAAA,GAAG,CAAE,SAAQoE,MAAM,CAACD,GAAI,EAArB,CAAH;AAEA,SAAO;AACLA,IAAAA,GAAG,EAAEC,MAAM,CAACD,GADP;AAELE,IAAAA,IAAI,EAAED,MAAM,CAACC;AAFR,GAAP;AAID,CA1ED;;AA4EA,MAAMO,qBAAqB,GAAG,CAACM,MAAD,EAASC,KAAT,KAAmB;AAC/C,SAAO,gBAAiBC,sBAAjB,GAA2C;AAChD,QAAIC,OAAO,GAAG,CAAd;;AAEA,eAAW,MAAMC,GAAjB,IAAwBJ,MAAxB,EAAgC;AAC9BG,MAAAA,OAAO,IAAIC,GAAG,CAACnE,MAAf;;AAEA,UAAIkE,OAAO,GAAGF,KAAd,EAAqB;AACnB,cAAMG,GAAG,CAACC,KAAJ,CAAU,CAAV,EAAaJ,KAAK,GAAGE,OAArB,CAAN;AAEA;AACD;;AAED,YAAMC,GAAN;AACD;AACF,GAdD;AAeD,CAhBD;;AAkBA,MAAMX,WAAW,GAAG,CAACa,KAAD,EAAQC,SAAS,GAAG1E,cAApB,KAAuC;AACzD,QAAMuE,GAAG,GAAGI,MAAM,CAACC,KAAP,CAAaF,SAAb,EAAwB,CAAxB,CAAZ;AAEA,QAAMP,MAAM,GAAG;AACb,KAACF,MAAM,CAACC,aAAR,GAAwB,UAAWW,YAAX,GAA2B;AACjD,aAAO,IAAP,EAAa;AACX,cAAMN,GAAG,CAACC,KAAJ,EAAN;AACD;AACF;AALY,GAAf;AAQA,SAAOX,qBAAqB,CAACM,MAAD,EAASM,KAAT,CAA5B;AACD,CAZD;;AAcA,MAAMV,kBAAkB,GAAG,iBAAkBP,OAAlB,EAA2B;AACpD,OAAK,IAAIsB,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGtB,OAAO,CAACpD,MAA5B,EAAoC0E,CAAC,EAArC,EAAyC;AACvC,eAAW,MAAMP,GAAjB,IAAwBf,OAAO,CAACsB,CAAD,CAAP,EAAxB,EAAsC;AACpC,YAAMP,GAAN;AACD;AACF;AACF,CAND;;AAQA,MAAMT,kBAAkB,GAAG,iBAAkBpC,MAAlB,EAA0BqD,MAA1B,EAAkC;AAC3D,MAAIC,KAAK,GAAG,CAAZ;;AAEA,aAAW,MAAMT,GAAjB,IAAwB7C,MAAxB,EAAgC;AAC9BsD,IAAAA,KAAK,IAAIT,GAAG,CAACnE,MAAb;AAEA,UAAMmE,GAAN;AACD;;AAED,aAAW,MAAMA,GAAjB,IAAwBQ,MAAM,CAACC,KAAD,CAA9B,EAAuC;AACrCA,IAAAA,KAAK,IAAIT,GAAG,CAACnE,MAAb;AAEA,UAAMmE,GAAN;AACD;AACF,CAdD","sourcesContent":["'use strict'\n\nconst log = require('debug')('ipfs:mfs:write')\nconst importer = require('ipfs-unixfs-importer')\nconst stat = require('./stat')\nconst mkdir = require('./mkdir')\nconst addLink = require('./utils/add-link')\nconst applyDefaultOptions = require('./utils/apply-default-options')\nconst createLock = require('./utils/create-lock')\nconst toAsyncIterator = require('./utils/to-async-iterator')\nconst toMfsPath = require('./utils/to-mfs-path')\nconst toPathComponents = require('./utils/to-path-components')\nconst toTrail = require('./utils/to-trail')\nconst updateTree = require('./utils/update-tree')\nconst updateMfsRoot = require('./utils/update-mfs-root')\nconst errCode = require('err-code')\nconst {\n  MAX_CHUNK_SIZE\n} = require('./utils/constants')\nconst last = require('async-iterator-last')\n\nconst defaultOptions = {\n  offset: 0, // the offset in the file to begin writing\n  length: undefined, // how many bytes from the incoming buffer to write\n  create: false, // whether to create the file if it does not exist\n  truncate: false, // whether to truncate the file first\n  rawLeaves: false,\n  reduceSingleLeafToSelf: false,\n  cidVersion: 0,\n  hashAlg: 'sha2-256',\n  format: 'dag-pb',\n  parents: false, // whether to create intermediate directories if they do not exist\n  progress: () => {},\n  strategy: 'trickle',\n  flush: true,\n  leafType: 'raw',\n  shardSplitThreshold: 1000\n}\n\nmodule.exports = (context) => {\n  return async function mfsWrite (path, content, options) {\n    log('Hello world, writing', path, content, options)\n    options = applyDefaultOptions(options, defaultOptions)\n\n    let source, destination, parent\n    log('Reading source, destination and parent')\n    await createLock().readLock(async () => {\n      source = await toAsyncIterator(content, options)\n      destination = await toMfsPath(context, path)\n      parent = await toMfsPath(context, destination.mfsDirectory)\n    })()\n    log('Read source, destination and parent')\n    if (!options.parents && !parent.exists) {\n      throw errCode(new Error('directory does not exist'), 'ERR_NO_EXIST')\n    }\n\n    if (!options.create && !destination.exists) {\n      throw errCode(new Error('file does not exist'), 'ERR_NO_EXIST')\n    }\n\n    return updateOrImport(context, path, source, destination, options)\n  }\n}\n\nconst updateOrImport = async (context, path, source, destination, options) => {\n  const child = await write(context, source, destination, options)\n\n  // The slow bit is done, now add or replace the DAGLink in the containing directory\n  // re-reading the path to the containing folder in case it has changed in the interim\n  await createLock().writeLock(async () => {\n    const pathComponents = toPathComponents(path)\n    const fileName = pathComponents.pop()\n    let parentExists = false\n\n    try {\n      await stat(context)(`/${pathComponents.join('/')}`, options)\n      parentExists = true\n    } catch (err) {\n      if (err.code !== 'ERR_NOT_FOUND') {\n        throw err\n      }\n    }\n\n    if (!parentExists) {\n      await mkdir(context)(`/${pathComponents.join('/')}`, options)\n    }\n\n    // get an updated mfs path in case the root changed while we were writing\n    const updatedPath = await toMfsPath(context, path)\n    const trail = await toTrail(context, updatedPath.mfsDirectory, options)\n    const parent = trail[trail.length - 1]\n\n    if (!parent.type.includes('directory')) {\n      throw errCode(new Error(`cannot write to ${parent.name}: Not a directory`), 'ERR_NOT_A_DIRECTORY')\n    }\n\n    const parentNode = await context.ipld.get(parent.cid)\n\n    const result = await addLink(context, {\n      parent: parentNode,\n      name: fileName,\n      cid: child.cid,\n      size: child.size,\n      flush: options.flush,\n      shardSplitThreshold: options.shardSplitThreshold,\n      format: options.format,\n      hashAlg: options.hashAlg,\n      cidVersion: options.cidVersion\n    })\n\n    parent.cid = result.cid\n\n    // update the tree with the new child\n    const newRootCid = await updateTree(context, trail, options)\n\n    // Update the MFS record with the new CID for the root of the tree\n    await updateMfsRoot(context, newRootCid)\n  })()\n}\n\nconst write = async (context, source, destination, options) => {\n  if (destination.exists) {\n    log(`Overwriting file ${destination.cid} offset ${options.offset} length ${options.length}`)\n  } else {\n    log(`Writing file offset ${options.offset} length ${options.length}`)\n  }\n\n  const sources = []\n\n  // pad start of file if necessary\n  if (options.offset > 0) {\n    if (destination.unixfs && destination.unixfs.fileSize() > options.offset) {\n      log(`Writing first ${options.offset} bytes of original file`)\n\n      sources.push(\n        () => {\n          return destination.content({\n            offset: 0,\n            length: options.offset\n          })\n        }\n      )\n    } else {\n      log(`Writing zeros for first ${options.offset} bytes`)\n      sources.push(\n        asyncZeroes(options.offset)\n      )\n    }\n  }\n\n  sources.push(\n    limitAsyncStreamBytes(source, options.length)\n  )\n\n  const content = countBytesStreamed(catAsyncInterators(sources), (bytesWritten) => {\n    if (destination.unixfs && !options.truncate) {\n      // if we've done reading from the new source and we are not going\n      // to truncate the file, add the end of the existing file to the output\n      const fileSize = destination.unixfs.fileSize()\n\n      if (fileSize > bytesWritten) {\n        log(`Writing last ${fileSize - bytesWritten} of ${fileSize} bytes from original file starting at offset ${bytesWritten}`)\n\n        return destination.content({\n          offset: bytesWritten\n        })\n      } else {\n        log('Not writing last bytes from original file')\n      }\n    }\n\n    return {\n      [Symbol.asyncIterator]: async function * () {}\n    }\n  })\n\n  const result = await last(importer([{\n    content: content\n  }], context.ipld, {\n    progress: options.progress,\n    hashAlg: options.hashAlg,\n    cidVersion: options.cidVersion,\n    strategy: options.strategy,\n    rawLeaves: options.rawLeaves,\n    reduceSingleLeafToSelf: options.reduceSingleLeafToSelf,\n    leafType: options.leafType\n  }))\n\n  log(`Wrote ${result.cid}`)\n\n  return {\n    cid: result.cid,\n    size: result.size\n  }\n}\n\nconst limitAsyncStreamBytes = (stream, limit) => {\n  return async function * _limitAsyncStreamBytes () {\n    let emitted = 0\n\n    for await (const buf of stream) {\n      emitted += buf.length\n\n      if (emitted > limit) {\n        yield buf.slice(0, limit - emitted)\n\n        return\n      }\n\n      yield buf\n    }\n  }\n}\n\nconst asyncZeroes = (count, chunkSize = MAX_CHUNK_SIZE) => {\n  const buf = Buffer.alloc(chunkSize, 0)\n\n  const stream = {\n    [Symbol.asyncIterator]: function * _asyncZeroes () {\n      while (true) {\n        yield buf.slice()\n      }\n    }\n  }\n\n  return limitAsyncStreamBytes(stream, count)\n}\n\nconst catAsyncInterators = async function * (sources) {\n  for (let i = 0; i < sources.length; i++) {\n    for await (const buf of sources[i]()) {\n      yield buf\n    }\n  }\n}\n\nconst countBytesStreamed = async function * (source, notify) {\n  let wrote = 0\n\n  for await (const buf of source) {\n    wrote += buf.length\n\n    yield buf\n  }\n\n  for await (const buf of notify(wrote)) {\n    wrote += buf.length\n\n    yield buf\n  }\n}\n"]},"metadata":{},"sourceType":"script"}